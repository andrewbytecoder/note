---

mindmap-plugin: basic

---

# 性能优化

## CPU
- 基本原理 ^3ab344ea-4b89-7c85
	- 进程
		- 进程和线程
			- 进程
				- 资源拥有的基本单位
				- task_struct: pid = tgid
			- 线程
				- 调度的基本单位
				- task_struct:pid != tgid
		- 状态
			- TASK_RUNNING
				- TASK_RUNNING 并不是说进程正在运行，而是表示进程在时刻准备运行的状态。
			- TASK_INTERRUPTIBLE
				- 因等待事件（比如IO事件）而进入睡眠
			- TASK_UNINTERRUPTIBLE
				- 因等待事件（比如IO事件）而进入睡眠，不可被信号唤醒
		- 调度
			- 调度策略
				- 普通调度策略
					- SCHED_NORMAL:普通进程
					- SCHED_BATCH:后台进程
					- SCHED_IDLE:空闲进程
				- 实时调度策略
					- SCHED_FIFO:高优先级的进程可以抢占低优先级的进程，而相同优先级的进程先到先得
					- SCHED_RR:高优先级的进程可以抢占低优先级的进程，而相同优先级的进程轮着来
					- SCHED_DEADLINE
			- 调度优先级
				- 实时进程：0~99
				- 普通进程：100~139
			- 调度器类
				- Fair:常用的策略为：SCHEDNORMAL、SCHEDBATCH、SCHED_IDLE
					- 完全公平算法-CFS
						- CFS对应的调度策略：SCHEDNORMAL、SCHEDBATCH、SCHED_IDLE。
						CFS 会为每一个进程安排一个虚拟运行时间 vruntime。如果一个进程在运行，随着时间的增加，进程的 vruntime 将不断增大。没有得到执行的进程 vruntime 不变。
						显然，那些 vruntime 少的，原来受到了不公平的对待，需要给它补上，所以会优先运行这样的进程。
						你可能会说，不还有优先级呢？如何给优先级高的进程多分时间呢？按比例！
				- Real_time:常用的策略为：SCHEDFIFO 和 SCHEDRR
	- 硬件中断处理
		- 关中断，处理时间很短
	- 软件中断处理
		- 开中断，处理时间可以很长
		- 留意网卡软件中断的执行
	- CPU上下文：包含cpu通用寄存器和PC指针等
		- 进程上下文切换
			- 1.同一进程的系统调用
			- 2.不同进程的调度切换
		- 线程上下文切换
		- 中断上下文切换
- 性能指标 ^2dd4312e-38fe-8a72
	- CPU使用率
	（用的好）
		- CPU使用率，就是除了空闲时间外的其他时间占总CPU时间的百分比，包含：用户CPU，iowait，硬件中断，软件中断等
		- 相关工具
			- top:
			top的输出：
			us: un-niced用户进程使用的cpu时间；
			ni: 被调整过nice值的进程占用的CPU使用率；
			wa:就是IO-wait；
				- 默认统计最近3秒的平均值
			- mpstat
			mpstat的输出和top不一样：
			%usr: 用户进程使用的cpu时间（包含un-niced和niced）；
			%nice: niced用户进程使用的cpu时间；
				- 显示所有cpu的指标，每隔1s输出一次
				mpstat -P ALL 1
			- pidstat
			pidstat输出:
			%user表示用户进程使用的cpu时间（包含un-niced和niced）；
			%wait表示任务等待运行时所占用的CPU百分比。
				- 显示所有进程的CPU指标，每隔1s输出一次
				pidstat -u 1
			- gdb
				- gdb调试需要中断程序运行，线上环境不允许
			- perf
				- 实时显示占用CPU时钟最多的函数或者指令
		- 实践
		- 调试技巧
			- us cpu占用高，说明用户态进程占用了较多的cpu，着重排查应用程序本身的代码逻辑问题
			- sy cpu占用高，说明内核态代码占用较多的CPU，所以应该着重排查内核线程或者系统调用的性能问题
			- wa cpu占用高，说明I/O完成所花的时间比较长，所以应该着重排查linux系统是不是存在I/O相关的性能瓶颈
			- hi和si占用高，说明软中断或者硬中断处理程序占用了较多的CPU，所以应该着重排查内核中的中断服务程序，一般是网络
			- 系统整体cpu使用较高，而实际的单个进程使用都不高，要考虑短时进程是否被频繁的创建和销毁
	- 平均负载
	（能用到）
		- 平均负载最理想的指标值是等于CPU的个数。
		平均负载为3，意味着：
		１、在只有3个CPU 的系统上，意味着所有的CPU都刚好被进程完全占用；
		２、在6个CPU的系统上，意味着CPU有50% 的空闲；
		３、在只有1个CPU 的系统中，则意味着2/3的进程竞争不到CPU；
		平均负载是一个综合性的指标，需要通过整体变化趋势来看系统是否有压力。
			- 平均负载是指单位时间内，系统处理可运行状态(Running)和不可中断等待状态(uninterruptible)的平均进程数
			- 相关工具
				- uptime
				- top
				- dstat -y
			- 调试技巧
				- 1.平均负载高可能是cpu密集型进程导致的
				- 2.平均负载高并不一定代表CPU使用率高，还有可能是等待I/O的进程变多了
				- 3.平均负载高的时候需要辅助其他工具来做进一步的分析
	- 上下文切换
	（无损耗）
		- 如果系统的上下文切换次数比较稳定，那么理想数据是１万以内。
			- 相关工具
				- vmstat
					- cs列：系统每秒上下文切换次数
					- r列：处于可运行状态的进程数量
					- b列：处于不可中断睡眠状态的进程数量
				- pidstat
					- 显示进程的每秒自愿和非自愿上下文切换次数：
					$pidstat -w
					cswch/s: 进程每秒自愿上下文切换的总数
					nvcswch/s:进程每秒非自愿上下文切换的总数
						- 当一个任务由于需要的资源不可用而阻塞时，就会发生自愿上下文切换。
						非自愿上下文切换发生在一个任务执行完其时间片段后被强制放弃处理器的情况下。
				- /proc/interrupts
				- /proc/softirqs
			- 调试技巧
				- 1.如果进程的资源上下文切换多了，表示进程在等待资源
				- 2.如果进程的非自愿上下文切换多了，说明进程在被强制调度（被实时性更高的进程抢占）
				- 3.如果中断次数多了，说明中断处理程序占用大量的CPU
				- 4.如果软中断次数多了，说明下半部分处理程序占用大量的CPU，一般就是指网络
- 工具汇总 ^f34910ed-8134-5a14
	- top
		- us: 代表用户态cpu时间，不包含被调整过nice值的进程所占的cpu时间；
		ni: 代表被调整过nice值的进程占用的cpu时间；
		sy: 代表内核态cpu时间
		id: 空闲时间，注意，它不包括等待 I/O 的时间（iowait）
		wa: 代表等待I/O的cpu时间
		hi: 代表硬件中断占据的cpu时间
		si: 代表软件中断占据的cpu时间
		void
		[例子]
		１、stress命令起1个进程：
		stress -c 1
		2、top查看
		3、renice
		renice -n 5 -p 26205
		4、top查看可见进程26205的cpu用量由原来的统计到us变成了统计到ni上
			- -p:只显示某个进程的状态
			- h：显示帮助
			- c：切换显示完整的命令行
			- M：根据常驻内存RES用量进行排序
			- P:根据CPU使用百分比大小进行排序
			- S：切换到累加模式
			- T：根据时间或者累计时间进行排序（TIME+列）
			- s：改变两次刷新的延迟时间，默认是3s
			- r：修改某个进程的nice值（对应TOP的NI列）
	- ps
		- 显示所有进程：
		void
		void
		ps -ef
		void
		void
		显示所有线程：
		void
		void
		ps -eLf或ps -eTf
			- ps统计的是进程的整个生命周期
			- -e：选择所有进程
			- -o：用于设定输出格式
				- 例如：
				-o stat,ppid,pid,cmd
				表示只输出进程的stat(状态信息)、ppid(父进程pid)、pid（当前进程的pid)，cmd(即进程的可执行文件）
			- -L Show threads. possibly with LWP and NLWP columns
			- -T Show threads, possibly with SPID column
			- -m Show threads after processes
			- -f 全格式输出
			- -a 选择所有子进程，除了session leader钰terminal不相关的进程
			- -A,选择所有进程，同-e
	- mpstat
		- mpstat -P ALL 1
	- sar
		- 前提条件：
		void
		sudo vi /etc/default/sysstat　　//把false修改为true
		sudo service sysstat restart　　//重启sysstat服务
	- pidstat
		- ％usr: 进程在用户态执行的cpu时间
		%system: 进程在内核态执行的cpu时间
		%wait: 进程等待运行时所花费的CPU时间
			- -u：输出进程CPU使用详情
			- -p：指定查看某个进程的信息
			- -U{usename}显示属于这个用户的进程
			- -r：内存
			- -d:I/O
				- KB_rd/s：该进程每秒从磁盘读取的数据大小
				- KB_wr/s：该进程每秒写入磁盘的数据大小
				- KB_ccwr/s：每秒取消写请求数据大小
				- iodelay：块I/O延迟，包括等待同步块I/O和换入块I/O结束的时间，单位是时钟周期
			- -R：进程的realtime priority and scheduling policy
			- -w：进程的上下文切换信息
				- cswch/s：每秒自愿上下文切换的次数
					- １、所谓自愿上下文切换，是指进程无法获取所需资源，导致的上下文切换。比如说， I/O、内存等系统资源不足时，就会发生自愿上下文切换；
					２、而非自愿上下文切换，则是指进程由于时间片已到等原因，被系统强制调度，进而发生的上下文切换。比如说，大量进程都在争抢 CPU 时，就容易发生非自愿上下文切换。
				- nvswch/s：表示每秒非自愿上下文切换的次数
			- -v：进程相关的线程数和文件描述符数量
			- -s：进程stack锁用内存信息
	- perf
		- 用法
			- perf list：列出所有能够触发perf采样点事件，类似/sys/kernel/debug/tracing/available_events的输出
			实测发现，perf支持的事件比ftrace多一倍左右
				- 对比：
				$ cat /sys/kernel/debug/tracing/availableevents | grep receiveskb
				net:netifreceiveskbentry net:netifreceive_skb
				$ perf list| grep receiveskb net:netifreceiveskb [Tracepoint event] net:netifreceiveskbentry [Tracepoint event]
			- perf probe:
			定义新的动态tracepoint
				- --add：添加一个probe event
				例如：perf probe --add do_sys_open
				- --del：删除probe event
				例如：perf probe --del probe:do_sys_open
				- 例子：perf record -e probe:do_sys_open -aR sleep 10
			- perf trace:
			类似strace，不过性能更佳，例如：perf trace ls
			- perf stat:
			运行命令并收集统计信息
				- $ perf stat ./main
				void
				task-clock:用于执行程序的cpu时间；
				context-switches：程序在运行过程中经历的上下文切换次数；
				page-faults：进程运行过程中产生的缺页次数；
				cpu-migrations：程序在运行过程中发生的CPU迁移次数，即被调度器从一个CPU转移到另外一个CPU上运行；
				instructions：该进程在这段时间内完成的CPU指令数；
				cycles：CPU时钟周期；
			- perf top:
			可以实时查看当前系统进程函数占用率情况
			- perf record:
			运行命令并保存profile到perf.data
				- -p：记录进程的events
				- -a：从所有的cpu上进行采集
				- -e：指定PMU(处理器监控单元)event，默认是cycles:ppp(CPU周期数)
				- -g：启用调用图（堆栈链/回溯）记录
				- -F：采样频率
				- 例如：
				perf record -p 12069 -a -g -F 99 --sleep 10
				perf record -e cpu-clock ./perftest
			- perf report:
			从perf.data中读取并显示profile
				- --no-children：不统计children开销
					- Self：记录的最后一列的符号，可以理解为函数本身的采样数占总采样数的百分比
					目的：找到最底层的热点函数
					- Children：记录的事这个符号调用的其他符号，理解为子函数，包括直接调用和间接调用的采样数之和占总采样数的百分比
					目的：找到较高层的热点函数
			- perf script:
			从perf.data中读取并显示详细的采样数据
			- perf kmem:
			跟踪/测量内核的内存属性
				- record：记录kmem events
					- --slab：记录slab申请器的events
					- --page：记录page申请器的events
				- stat：报告内核内存统计信息
					- --slab：统计slab申请器的events
					- --page：统计page申请器的events
			- perf mem：分析内存访问
			- perf lock：分析锁性能
			- perf kvm：针对kvm虚拟化分析
			- perf sched：分析内核调度器性能
				- record：采集和记录scheduling events
				例如全局：perf sched record -- sleep 10
				例如进程：perf sched record -p 19357 --sleep 10
			- 火焰图
				- 火焰图的横轴和纵轴的含义：
				横轴表示采样数和采样比例。一个函数占用的横轴越宽，就代表它的执行时间越长。同一层的多个函数，则是按照字母来排序。
				纵轴表示调用栈，由下往上根据调用关系逐个展开。换句话说，上下相邻的两个函数中，下面的函数，是上面函数的父函数。这样，调用栈越深，纵轴就越高。
				火焰图不包含任何时间的因素，所以并不能看出横向各个函数的执行次序。
		- 场景
			- 1.寻找热点函数，定位性能瓶颈
				- 具体实现是对事件进行采样，然后再根据采样数，评估各个函数的调用频率
			- 2.perf课可以用来分析CPU cache、CPU迁移、分支预测、指令周期等各种硬件事件
			- 3.perf也可以只对感兴趣的事件进行动态跟踪
		- 实践过程
			- 1.寻找热点函数，定位性能瓶颈
			- 2.自定义追踪函数
				- 1、添加 dosysopen 探针
				$ perf probe --add dosysopen
				2、采样和追踪
				$ perf record -e probe:dosysopen -aR sleep 1
				3、查看采样结果
				$ perf script
				4、删除探针
				$ perf probe --del probe:dosysopen
	- pstree
		- 经典用法：
		$ pstree -p 5638
		显示5638这个进程的进程树（包含线程）
		$ pstree -T -p 5638
		显示5638这个进程的进程树（不包含线程）
			- -a：显示命令行参数
				- If the command line of a process is swapped out，则该进程将显示在括号中，例如类似这样：
				-{kubeensaas}(8)
			- -c：禁止压缩子树（压缩后不显示子树信息）
			- -n：通过pid而不是name对相同祖先进程进行排序
			- -g：显示PGIDs
			- -p：显示某个进程的进程树（包含线程）
			- -T：隐藏线程，只显示进程
	- taskset
		- -pc 0x3 pid： 绑定CPU0和CPU3到进程
		- -pc pid：产看进程绑定的CPU(输出位3，也就是0x11，表示0,1cpu)
	- cpulimit
		- -p pid -l percent：进程允许的cpu使用量为percent %
		- -k：如果进程cpu超量，直接杀掉进程而不是显示cpu使用（默认）
		- -m：输出统计信息
	- pstack
		- 用法
			- {pid}对指定的PID的进程输出函数调用栈
		- 场景
			- 应用正常运行时查看stack trace信息
	- strace
		- 用法
			- -p {pid}
			- -f：跟踪子进程
			- -t：在输出的每一行前加上时间信息
			- -T：显示每一个系统调用所耗的时间
			- -c：统计每一个系统调用的次数，错误次数，执行时间和执行时间占比
			- -i：输出系统调用的入口指针
			- -e expr：指定一个表达式，用来控制如何跟踪
				- expr格式如下:
				[qualifier=][!]value1[,value2]...
				qualifier只能是 trace,abbrev,verbose,raw,signal,read,write,fault和inject其中之一;
				value是用来限定的符号或数字；
				默认的 qualifier是 trace；
				感叹号是否定符号；
				例如：
				-eopen等价于 -e trace=open
				表示只跟踪open调用
				-e trace=file
				只跟踪有关文件操作的系统调用.
				-e trace=process
				只跟踪有关进程控制的系统调用.
				-e trace=network
				跟踪与网络有关的所有系统调用.
				-e strace=signal
				跟踪所有与系统信号有关的 系统调用
				-e trace=ipc
				跟踪所有与进程通讯有关的系统调用
			- -o {file}：保存到file这个文件
		- 场景
			- 1.正在运行的程序实际读取的是哪个配置文件？
			- 2.程序好像hang住了，具体是什么情况，为什么会hang住？hang在哪里了？
			- 3.进程运行很慢，但是没有源码，向看看时间都是花在了哪里？
			- 4.容器环境下，如何对应用程序进行调试和追踪？
	- stap
		- stap --all-modules dropwatch.stp
	- /proc
		- 通过子进程pid查看父进程ppid：cat /proc/{pid}/status |grep PPid
- 调优实践 ^bb40cea8-5349-4ec2
	- 1.用户cpu使用率高，如果找到代码瓶颈点？
		- 分析过程
			- 1.通过top命令查看系统整体的cpu使用率和平均负载
			- 2.pidstat -u 1|more 查看进程的cpu使用率，找到可疑进程
			- 3.pstree -p {pid}查看进程的进程结构（继承关系）
			- 4.strace -f -p {pid}追踪进程的系统调用情况，是否存在频繁的系统调用？
			- pstack {pid}找到代码瓶颈点
		- $ cat /tftpboot/test.sh
		!/bin/bash
		stress --cpu 1 --timeout 12000
	- 2.软中断使用率高，如何找到代码瓶颈点？
		- 分析过程
			- 1.通过top命令查看系统整体的CPU使用率和平均负载
			- 2.watch -d cat/proc/softirqs 找到瓶颈所在的软件中断
			- 3.perf record -g采集内核事件
			- 4.perf report 分析事件，找到瓶颈所在的内核函数代码
		- 环境搭建
			- host A（本机）:
			iperf -s -p 10000
			host B:
			iperf -c 172.21.92.104 -p 10000 -t 10000
	- 3.cpu使用率较高，居然是它造成的
		- 分析过程
			- 1.通过top命令查看系统整体的cpu使用率和平均负载
			- 2.pidstat -u 1|more：查看进程的cpu使用率找到可疑进程
			- 3.iostat查看系统整体I/O情况
			- 4.iotop查看进程的I/O压力情况
			- 5.strace -f -p {pid}追踪进程的系统调用情况，是否存在频繁的系统调用
		- 环境搭建
			- 给出一个频繁打开文件，写入一点数据然后再关闭文件的示例
- 调优方法 ^01280bfb-3b2d-2be8
	- 应用层面
		- 1.算法优化，以排序为例，相同量级的数据，快排比冒泡排序节省cpu
		- 2.进程优先级调整
		- 3.异步处理
		- 4.多线程替代多进程
	- 系统层面
		- 1.CPU绑定：
		把进程绑定到一个或多个cpu,减少跨 CPU 调度带来的上下文切换问题
		- 2.中断负载均衡，echo {1,2,4,8,10,20,40,80} > /proc/irq/129/smp_affinity

## I/O
- 基本原理 ^73251ede-81fe-5578
	- 应用层I/O操作
		- 是否利用标准库缓存
			- 非缓冲I/O
				- 系统调用提供，如：open, read, write, close等
			- 缓存I/O
				- C语言标准输入输出库，如：fopen, fclose, fread, fwrite, fgets, fputc, fputs等
		- 是否利用内核里的页缓存
		open(2), O_DIRECT
			- 直接I/O
				- 跳过操作系统的文件缓存，直接跟文件系统交互来访问文件
			- 非直接I/O
				- 需要经过操作系统的文件系统
		- 是否阻塞自身运行
		open(2), O_NONBLOCK
			- 阻塞I/O
			- 非阻塞I/O
		- 连续I/O和随机I/O
			- 连续I/O
				- read->read->read
				write->write->write
			- 随机I/O
				- lseek->read
				lseek->write
	- 虚拟文件系统
		- 文件缓存
		- inode缓存
		- dentry缓存
	- I/O内核架构
		- https://ny5odfilnr.feishu.cn/file/CpswbJaVMoKXI6xHxOrc94vAnid?from=from_copylink
		- 通用块设备层
			- 通用块设备层，包括块设备 I/O 队列和 I/O 调度器。它会对文件系统的 I/O 请求进行排队，再通过重新排序和请求合并，然后才要发送给下一级的设备层。
			- I/O队列
				- 对文件系统的 I/O 请求进行排队，再通过【重新排序】和【请求合并】，然后把请求发送到块设备驱动层。
			- I/O调度
				- I/O调度指对I/O请求进行排序的过程。Linux 内核支持四种 I/O 调度算法，分别是 NONE、NOOP、CFQ 以及 DeadLine。
				查看和修改某个块设备的IO调度器：
				$ cat /sys/block/sda/queue/scheduler
				noop deadline [cfq]
				- NONE
					- 完全不使用任何 I/O 调度器，常用在虚拟机中。
				- NOOP(电梯电镀程序)
					- 它实际上是一个先入先出的队列，只做一些最基本的请求合并（类似电梯算法），常用于闪存、SSD等存储。
					NOOP倾向饿死读而利于写！
				- CFQ(完全公平排队I/O调度器)
					- CFQ是现在很多发行版的默认 I/O 调度器，它为【每个进程】维护了一个 I/O 调度队列，并按照时间片来均匀分布每个进程的 I/O 请求。
					类似于进程 CPU 调度，CFQ 还支持进程 I/O 的优先级调度。
					CFQ试图均匀地分布对I/O带宽的访问,避免进程被饿死并实现较低的延迟。
				- DeadLine(截止时间调度程序)
					- DeadLine 调度算法，分别为读、写请求创建了不同的 I/O 队列，可以提高机械磁盘的吞吐量。DeadLine 调度算法，多用在 I/O 压力比较重的场景，比如数据库等。
		- 块设备驱动层
			- 负责最终物理设备的I/O操作
				- HDD
					- 1.寻道时间
					- 2.旋转时间
					- 3.数据传输时间
					- https://blog.csdn.net/qyxls/article/details/117322123
				- SSD
- 性能指标 ^22f67ed9-64a8-e5a3
	- 磁盘用量、剩余等
		- 相关工具
			- df -h
	- inode节点用量、剩余等
		- inode节点空间不足，但是磁盘空间充足，可能是过多小文件造成的！
		- 相关工具
			- df -i
				- mount -t tmpfs -o size=1G tmpfs /tftpboot/minio
	- 使用率：磁盘处理I/O时间占比
		- 相关工具
			- iostat -d -x -p sda (%util)
				- r/s:设备每秒完成的读请求数(合并后)；
				w/s:设备每秒完成的写请求数(合并后)；
				rkB/s:每秒从磁盘读取的数据量；
				wkB/s:每秒向磁盘写入的数据量；
				rrqm/s:每秒排队到设备上的合并的读请求数；
				wrqm/s:每秒排队到设备上的合并的写请求数；
				rawait:读请求处理完成等待时间，包括队列中等待时间和设备实际处理所花的时间，单位是毫秒 wawait:写请求处理完成等待时间，包括队列中等待时间和设备实际处理所花的时间，单位是毫秒
				aqu-sz:平均请求队列长度
				rareq-sz:读请求的平均数据量大小（单位是KB）
				wareq-sz：写请求的平均数据量大小（单位是KB）
				svctm：处理I/O请求所需的平均时间（单位是毫秒），该指标不准，后续会移除。
				%util：磁盘处理I/O的时间百分比
				【几个重要的指标】
				磁盘 I/O 使用率 --> %util
				每秒I/O读请求数 --> r/s
				每秒I/O写请求数　--> w/s
				每秒I/O读请求大小　--> rkB/s
				每秒I/O写请求大小　--> wkB/s
				读响应时间 --> rawait 写响应时间 --> wawait
		- 局限
			- 对于RAID和SSD，该指标不能反映其真是性能
	- 每秒I/O请求数（读，写）
		- 相关工具
			- iostat -d -x -p sda (r/s, w/s)
			- dstat -d
	- 每秒I/O请求大小（读，写）
		- 相关工具
			- iostat -d -x  -p sda (rkB/s, wkB/s)
			- dstat -d
	- 响应时间：I/O请求从发出到收到响应时间间隔（读，写）
		- 相关工具
			- iostat -d -x -p sda (r_await, w_await)
	- 进程I/O大小或者I/O延迟
		- 相关工具
			- pidstat -d
				- kB_rd/s：该进程每秒从磁盘读取的数据大小
				- kB_wr/s：该进程每秒写入磁盘的数据大小
				- kB_ccwr/s：每秒取消写请求数据大小，当任务截断一些脏页缓存时可能发生这种情况
				- iodelay：块I/O延迟，包括等待同步块I/O完成事件和换入块I/O的时间，单位是时钟周期
			- iotop
			I/O：进程在等待I/O上花费的时间占比(%)
			- biotop
			AVms：进程平均I/O时间，单位是ms
	- 进程每次I/O操作的I/O延迟
		- 相关工具
			- biosnoop-bpfcc -Q
			LAT(ms)：磁盘I/O的延迟，包括请求提交给设备到请求完成的时间
	- 文件缓存
		- 相关工具
			- 查看整体：
			cat /proc/meminfo | grep "^Cached"
			- 单个文件：
			pcstat /home/user/test
			- 释放文件缓存：
			echo 1 > /proc/sys/vm/drop_caches
	- dentry和inode缓存
		- dentry缓存
		(dcache)
			- 相关工具
				- cat /proc/slabinfo | grep -E '^#|dentry'
		- inode缓存
		（icache）
			- 相关工具
				- cat /proc/slabinfo | grep -E '^#|inode'
		- 释放： echo 2 > /proc/sys/vm/drop_caches
		释放前后对比查看：cat /proc/meminfo | grep SReclaimable
- 工具汇总 ^c14aa304-85ea-1878
	- iostat
		- 用法
			- -c：显示cpu指标
			- -d：显示磁盘使用情况
			- -k：以KB为单位显示
			- -m：以MB为单位显示
			- -x：显示详细信息
			- -p：显示某个磁盘或者分区的使用情况
	- dstat
		- 用法
			- -m：显示内存使用情况
			- -c：显示cpu使用情况
			- -n：显示网络状况
			- -I：显示系统负载情况
			- -r：显示I/O请求读写请求数
			- -d：磁盘读写情况
			- -y：显示中断和上下文切换次数等
			- --socket：显示套接字(tcp, udp)的个数
			- --top-io：显示消耗I/O最大的进程
			- --top-cpu：显示消耗cpu最大的进程
			- --top-cputime：显示使用cpu时间最大的进程(ms)
			- --top-latency：显示总延迟最大的进程(ms)
			- --top-mem：显示使用内存最大的进程
			- dstat -cmrdn 显示所有CPU，内存，磁盘和网络的情况，通常用于整体查看问题出现在哪个位置
	- pidstat
		- 用法
			- -d：统计进程的I/O大小以及I/O延迟
	- iotop
		- 前两行分别表示，进程的磁盘读写大小总数和磁盘真实的读写大小总数。
		TID/PID：线程ID/进程ID；
		PRIO：I/O 优先级；
		USER：用户名；
		DISK READ：每秒读磁盘的大小；
		DISK WRITE：每秒写磁盘的大小；
		SWAPIN：进程在SWAPIN上花费的时间占比；
		IO：进程在等待I/O上花费的时间占比；
		- 用法
			- 不加任何参数显示所有线程的I/O使用情况
			- -P：只显示进程的I/O使用情况
			- -o：只显示实际执行I/O的进程或线程，而不是显示所有的进程或线程
			- -p：显示某个进程的I/O使用情况
			- -u：显示用户的I/O使用情况
	- ionice
		- ionice对进程的IO调度class and priority，的设置只有当调度算法是CFQ时才是有效的。
		- 当需要进行I/O优化时可以使用，指定优先级之后可以被优先调用
		- 用法
			- -c：指定调度策略
			0 for none, 1 for real time, 2 for best-effort, 3 for idle
			- -n {classdata}：指定I/O优先级别
			classdata表示I/O优先级别，对于best effort和real time，classdata可以设置为0-7,0的优先级别最高
			- -p {pid} ：指定要查看或者设置的进程号或者线程号
	- strace
		- 用法
			- 追踪进程的I/O系统调用
	- filetop
		- filetop实时追踪文件的读写情况。
		TID：线程ID
		COMM：线程命令行
		READS：读取次数
		WRITES：写入次数
		R_Kb：读取字节数
		void
		W_Kb：写入字节数
		T：文件类型
		FILE：文件名称
		- 用法
			- -a：包含非常规文件，例如：sockets,FIFOs等
			- -C：不清屏
			- -r：最多打印行数，默认为20
			- -s {all, reads, writes, rbytes, wbytes}：指标排序，默认是rbytes
			- -p {pid}：只追踪{pid}这个进程的文件读写情况
			- 每隔5s打印一次，共打印10次
			filetop 5 10
	- biotop
		- I/O：读或者写的I/O次数
		Kbytes：读或者写的字节数
		AVGms：平均I/O时间，单位是ms
		（统计的是当前时间周期的数据）
		- 实时显示，可以长时间运行查看某段时间进程的IO情况
		- 用法
			- 追踪进程I/O并按I/O吞吐量大小进行排序，默认1s统计一次
			- -C：不清屏
			- 设置每隔5秒打印一次，共打印10次：
			biotop 5 10
	- biosnoop
		- LAT(ms)：磁盘I/O的延迟，包括请求提交给设备到请求完成的时间统计。
		- 用法
			- 追踪并打印进程访问I/O的内核事件
			- -Q： include OS queued time
			- -d {DISK}：Trace this disk only
		- biotop查看之后，使用该命令查看具体进程在干那些I/O相关的操作
	- biolatency
		- 用法
			- 直方图的方式统计系统I/O延迟(单位us)
			- -T：在输出包里包含时间戳
			- -Q：include OS queued time in I/O time
			- -m：按照ms统计系统I/O延迟
			- -D：分开打印各个磁盘的直方图
			- 输出带时间戳，每秒输出一次，共输出5次：
			biolatency -T 1 5
	- blktrace
		- 第一个字段：主、次设备号;
		第二个字段：cpu号;
		第三个字段：序列号;
		第四个字段：时间戳;
		第五个字段：本次I/O对应的进程 ID;
		第六个字段：Event，这个字段非常重要，反映了 I/O 进行到了哪一步;
		第七个字段：R 表示 Read， W 是 Write，S表示sync;
		第八个字段：223490+56，表示的是起始 block number 和 number of blocks，即我们常说的Offset 和 Size;
		第九个字段：进程名字;
		void
		第六个字段Event:
		A:IO被重新映射到不同的设备；
		Q:将要被 request 代码处理（即将生成 I/O 请求）；
		G: I/O 请求（request）生成，为 I/O 分配一个 request 结构体；
		P:插入I/O请求
		U:准备向磁盘驱动发送该 I/O
		D:IO发给driver去处理
		C:IO处理完毕
		- 用法
			- 采集
			blktrace -d /dev/vda1
			- 分析:
			blktrace -i vda1
			- 例子：
			blktrace -d /dev/vda1 -o - | blkparse -i -
	- fio
		- 进行I/O基准测试
- 调优实践 ^b1b873a6-4d9c-3bb6
	- 1.linux遇到I/O性能问题，如何进行一步一步的调试？
		- 分析过程
			- Sub title
				- 1. 查看系统整体I/O使用情况
				iostat -d -x -p sda 1
				top 验证
			- 2.查看所有进程的I/O使用情况，找出可疑的进程
			pidstat -d 1
			- 3.追踪可疑进程（子进程）的系统调用情况
			strace -f -p {pid}
			- 4.show出可疑进程的子进程树：
			pstree {pid}
	- 2.如何针对linux应用程序的I/O访问行为，具体分析每一步的时间开销？
		- 分析过程
			- 1.biosnoop查看进程实时读写情况
			- 2.blktrace -d /dev/vda1 -o  -|blkparse -i -
				- Q->G：生成 I/O 请求所消耗的时间；
				G->P：I/O 请求进入 I/O Scheduler 所消耗的时间；
				P->D: I/O 请求在 I/O Scheduler 中等待的时间；
				D->C：I/O 请求在 Driver 和硬件上所消耗的时间，可以作为硬件性能的指标；
				void
				Q->C：整个 I/O 请求所消耗的时间(Q->G + G->P + P->D + D->C = Q2C)，相当于 iostat 的 await。
	- 3.rm删除的文件还能找回来吗？能、但是得分情况！
		- 实践过程
			- 1.创建文件：/app/test.c
			- 2.删掉文件
			rm /app/test.c
			- 3.恢复过程
				- Sub title
					- 1.
				- Sub title
					- 2.
			- 4.前提条件是在系统中有一个打开该文件，并还在运行的进程存在
		- 实践总结
			- 1.文件对象（struct file）是已打开的文件在内存中的表示
			- 2.由于多个进程可以打开和操作同一个文件，所有同一个文件也可能存在多个文件对象
			- 3.虽然一个文件对应的文件对象不是唯一的，但是对应的索引节点(struct inode)和目录页(stuct dentry)对象是唯一的
			- 4.rm命令底层调用了unlinkat()函数
			- 5.unlinkat()：如果文件对象是对文件的最后一个引用，且没有进程正在打开这个文件，才会真正的删除文件，否则文件依然存在内存里，这样文件就可以被恢复。
- 调优方法 ^4f6a96e5-28d4-66da
	- 应用程序优化
		- 1.追加写代替随机写
		- 2.充分利用缓存（包括系统缓存和标准库缓存），降低实际I/O的次数
		- 3.可以在应用程序内部构建自己的缓存，或者用redis/memcached这类外部缓存系统
		- 4.需要进行同步写的场景中，尽量将写请求合并，而不是每个请求都同步写入磁盘，既可以用fsync()取代O_SYNC
		- 5.在使用CFQ调度器时，使用inode调整进程的I/O调度优先级
			- 在使用 CFQ 调度器时，可以用 ionice 来调整进程的 I/O 调度优先级，特别是提高核心应用的 I/O 优先级。
			void
			void
			ionice 支持三个优先级类：Idle、Best-effort 和 Realtime。
			void
			void
			其中， Best-effort 和 Realtime 还分别支持 0-7 的级别，数值越小，则表示优先级别越高。
	- 文件系统优化
		- 1.文件系统的缓存
			- 比如，你可以优化 pdflush 脏页的刷新频率（比如设置 dirtyexpirecentisecs 和 dirtywritebackcentisecs）以及脏页的限额（比如调整 dirtybackgroundratio 和 dirty_ratio 等）。
			void
			备注：以上配置都在/proc/sys/vm/目录下。
		- 2.优化内核回收目录项缓存和索引节点缓存的倾向
			- 可以优化内核回收目录项缓存和索引节点缓存的倾向，即调整 vfs cache pressure（/proc/sys/vm/vfs
			cache pressure，默认值 100），数值越大，就表示越倾向于回收目录项缓存和索引节点缓存占用的内存。
		- 3.使用tmpfs，获得更好的I/O性能
			- 磁盘文件
			- tmpfs
				- 将原先在磁盘文件上的文件放到tmpfs文件上
				- 1、创建tmpfs
				mkdir -p /tftpboot/tmp
				mount -t tmpfs -o size=1G tmpfs /tftpboot/tmp
				２、复制csv文件到tmpfs文件系统目录
				３、建表
				spark-sql>
				CREATE table tmpfile
				USING csv
				OPTIONS (
				header true,
				path "/tftpboot/tmp/test.csv"
				);
				4、查询
				spark-sql>
				select * from tmpfile where name="name23453";
	- 磁盘优化
		- 1.使用SSD替代HDD
		- 2.针对磁盘和应用程序I/O模式的特征，我们可以选择最合适的I/O调度算法
		- 3.在顺序读比较多的场景中，我们可以增大磁盘的预读数据
			- 你可以通过下面的proc文件，调整 /dev/sda 设备的预读大小：
			$ cat /sys/block/sda/queue/readaheadkb
			128
			默认大小是 128，单位为 KB。
		- 4.课可以优化内核块设备I/O选项
			- 比如，可以调整磁盘队列的长度 /sys/block/sda/queue/nr_requests。
			void
			void
			适当增大队列长度，可以提升磁盘的吞吐量。

## 网络
- 基本原理 ^adf6b9a6-b78c-564b
	- TCP/IP五层模型
		- 应用层
			- 负责应用程序沟通
				- 常见协议
					- http
					- ftp
					- tftp
					- snmp
					- smtp
					- telnet
					- websocket
		- 传输层
			- 提供端到端的通信服务
				- 常见协议
					- tcp
					- udp
		- 网络层
			- 负责数据的分片，寻址和路由
				- 常见协议
					- ip协议
		- 数据链路层
			- 负责硬件设备之间的数据帧的传送和识别，例如同帧同步、冲突检测
				- 常见协议
					- ethernet协议
		- 物理层
			- 透明传输比特流
				- 常见硬件厂商
					- broadcom：博通
					- realtek：瑞昱
					- intel
	- linux网络设备驱动
	（以dm9000芯片为例）
		- 硬件datasheet
			- https://www.davicom.com.tw/pddocs/DM9000A-DS-F01-030311.pdf
		- 最大传输单元mtu
			- mtu范围: [68, 1500]
				- ip报头最小: 20bytes
				- tcp头部最小：20bytes
				- 最大mss= 1500 - 20 -20=1460
					- 最大报文段长度（MSS）是TCP协议的一个选项，用于在TCP连接建立时，收发双方协商通信时每一个报文段所能承载的最大数据长度（不包括文段头）。
					MSS = MTU - TCP头部大小 - IP头部大小
					其中，TCP 头部和 IP 头部的大小是固定的，分别为 20 字节和 20 字节。
			- mtu限制了数据链接层上可以传输的数据包大小，也因此限制了上层（IP层）的数据包大小
			- mtu和IP分片的关系
				- 当要求发送的IP数据包比数据链路层的MTU大时，必把该数据包分割成多个IP数据包才能发送。
		- linux网卡驱动的发送和接收
			- 参考：linux, drivers/net/ethernet/davicon/dm9000.c
			- 网卡驱动整体框架
			- 数据帧发送
				- 1.dm9000_start_xmit()
				- Sub title
					- 2. dm9000_interrupt()
				- 3.dm9000_tx_done
			- 数据帧接收
				- 1.dm9000_interrupt()
				- 2.dm9000_rx()
				- 3.netif_rx()
		- 软中断NET_TX,NET_RX处理
			- 参考：net/core/dev.c
			- 网络底半部发送
				- net_tx_action()
			- 网络底半部接收
				- net_rx_action()
- 性能指标 ^f6daf7f4-836d-f922
	- 最大传输单元mtu
		- 相关工具
			- 查看
			ifconfig eth0 | grep mtu
			- 修改（临时）：
			ifocnfig eht0 mtu 1450
		- 实践：IP数据包（包含IP头）超过MTU大小，会发送什么情形？
			- 【假设】eth0接口的mtu为1500！
			命令１：
			ping -I eth0 -s 147２ -M do 192.168.0.101
			命令２：
			ping -I eth0 -s 1473 -M do 192.168.0.101
	- 带宽：链路的最大传输速度，单位b/s(比特/s)，属于基础设施
		- 相关工具
			- ethtool eth0 |grep Sepeed
	- PPS： Packet per second，表示以网络包围单位的传输速率
		- 相关工具
			- sar -n DEV
	- 吞吐量：单位时间内传输的数据量，单位b/s或者B/s
		- 相关工具
			- sar -n DEV
	- 往返延时(RTT)
		- RTT(Round-Trip Time): 往返时延。在计算机网络中它是一个重要的性能指标，表示从发送端发送数据开始，到发送端收到来自接收端的确认（接收端收到数据后便立即发送确认），总共经历的时延。
		- 相关工具
			- 【ICMP】ping -c4 8.8.8.8
				- ping命令的输出中的最后一行：
				rtt min/avg/max/mdev = 58.325/71.634/94.710/14.502 ms
				mdev全称Mean Deviation，译为平均方差
				mdev越大，表示网络越不稳定。
				- 用来查看网络是否稳定
			- 【TCP】hping3 -c 3 -S -p 80 httpbin.org
	- tcp半连接队列的大小
		- 相关工具
			- max(64, net.ipv4.tcp_max_syn_backlog)
	- tcp全连接队列大小
		- 相关工具
			- min(backlog, net.core.somaxcon)
	- tcp/udp吞吐量
		- 相关工具
			- tcp
				- server
					- iperf -s -p 10000
				- client
					- iperf -c 192.168.1.102 -p 10000
			- udp
				- server
					- iperf -s -p 10000
				- client
					- iperf -u -c 192.168.1.102 -p 10000
	- tcp缓冲区大小
		- 相关工具
			- tcp发送缓冲区大小
				- cat /proc/sys/net/ipv4/tcp_wmem
				- min
				- default
				- max
				- 修改：sysctl -w net.ipv4.tcp_wmem="xxx xxx xxx"
			- tcp接收缓冲区
				- cat /proc/sys/net/ipv4/tcp_rmem
				- min
				- default
				- max
				- 更改：sysctl -w net.ipv4.tcp_rmem="xxx xxx xxx"
	- udp缓存区大小
		- 相关工具
			- udp缓冲区大小
				- cat /proc/sys/net/udp_mem
				- min
				- default
				- max
	- socket连接数
		- 相关工具
			- 查看tcp连接状态为SYN_REC的sockets：
			netstat -n -p -t | grep  SYN_REC
			- 查看tcp连接状态为SYN_REC的sockets:
			ss -n -p -t |grep SYN_REC
	- 套接字缓冲区大小
		- 单个套接字缓冲区大小
			- 相关工具
				- setsocketopt(,,,SO_SNDBUF,,,)配置
					- 在调用connect或listen之前通过setsockopt设置
				- setsocketopt(,,,SO_RCVBUF,,,)配置
					- 在调用connect或listen之前通过setsockopt设置。
		- 内核全局的套接字缓冲区大小
			- 相关工具
				- 套接字接收缓冲区大小
					- cat /proc/sys/net/core/rmem_max
					- 修改：sysctl -w net.core.rmem_max=xxx
				- 套接字发送缓冲区大小
					- cat /proc/sys/net/core/wmem_max
					- 修改：sysctl -w net.core.wmem_max=xxx
- 工具汇总 ^86c57e31-7c4f-3147
	- wireshark
		- 用法
			- 过滤器
				- 捕获过滤器：用于决定捕获什么数据
				- 显示过滤器：在捕获结果中进行详细查找
					- Syntax: Protocal·String·String·Comparison operator·Value·Logical Operator·Other expression
					Example: ftp  passive ip == 10.2.3.4 xor icmp.type
					- 比较运算
						- eq:==
						- ne:!=
						- gt:>
						- lt:<
						- ge:>=
						- le:<=
					- 逻辑运算
						- and:&&
						- or:||
						- Xor:^^
						- not:!
					- 例子
						- frame.cap_len > 100
						cap_len长度包括：以太网头+ip头+tcp头+应用数据的总长度
						- ip.len >= 100
						ip.len是ip层以上的（包含ip头）数据的总长度
						- tcp.len >= 60
						tcp.len即tcp segment len，指的是tcp所承载的应用数据的长度(不包含tcp头部)
						- udp.length > 100
						udp.length是udp包头和udp载荷数据的总大小
						- 对多条诗句进行过滤
						ip.addr==192.168.1.102 and tcp.flag.fin
						- 按照字节位置的内容进行过滤（十六进制）：
						tcp[0:2]==ac3a(匹配源端口号为44090)
						tcp[n,m]:n是起始位置，m是从指定位置的区域长度
						- 按bit位置的内容进行过滤
						tcp[13]&2
						&2取这个字节中第2位即SYN位置的值
						- tcp.segment_data_contains  49:12:45:qf:93:09
						数据段是够包含指定的内容序列
			- Flow Graph
				- 1, 在选择一个包后，单击右键并选择 “Follow” -> “TCP Stream”；
				2，关闭弹出来的对话框，回到 Wireshark 主窗口。这时候，你会发现 Wireshark 已经自动帮你设置了一个过滤表达式，例如：tcp.stream eq 24。
				从这里，你可以看到这个 TCP 连接从三次握手开始的每个请求和响应情况。
				3，为了更加直观，你可以继续点击菜单栏里的 Statics -> Flow Graph，选中 “Limit to display filter” 并设置 Flow type 为 “TCP Flows”。就可以看到更直观的通信细节。
	- tcpdump
		- 用法
			- -i eth0：指定网络接口
			- -nn：不解析ip地址和端口号名称
			- -c {count}：指定要抓取的数据包个数
			- -w {file}：抓包并保存到文件，比如test.pcap
			- 过滤表达式和wireshark类似
				- 主机过滤
					- tcpdump -nn host 192.168.1.100
					- host
					- src host
					- dst host
				- 端口过滤
					- port
					- src port
					- dst port
				- 协议过滤
					- ip
					- ip6
					- arp
					- tcp
					- udp
					- icmp
				- 逻辑表达式
					- and
					- or
					- not
				- 特定状态的TCP包
					- tcp[tcoflages]
			- 输出格式
				- 时间戳
				- 协议
				- 源IP地址:源端口
				- 目的IP地址:目的端口
				- 网络包详细信息
			- 例子
				- tcpdump -i eth0 icmp and host 192.168.1.102 -nn
				- tcpdump -i eth0 -w test.pcap
	- netstat
		- 用法
			- -a：显示所有socket连接(包括listening和non-listening)
			- -l：只显示listening状态和socket连接
			- -n：表示显示数字地址和端口而不是名字
			- -p：表示显示进程信息
			- -t：只显示tcp连接（若不执行-l，则默认仅显示non-listening连接）
			- -u：只显示udp连接(若不指定-l,则默认只显示non-listening的连接)
			- -x：只显示unix连接
			- -i：显示所有网络接口的状态
			- -s：胡总了ip、icmp、udp、tcp等各种协议的收发统计信息
				- Ip:
				Forwarding: 1 //开启转发
				8641328 total packets received //总收包数
				73 with invalid addresses // 有着错误地址的封包数
				0 forwarded //转发包数
				0 incoming packets discarded //接收丢包数
				8598954 incoming packets delivered //接收的数据包数
				5161967 requests sent out //发出的数据包数
				160 dropped because of missing route //找不到路由而导致的丢包数
				1 fragments dropped after timeout　//超时导致的丢包数
				274 reassemblies required　//需要重组的封包数
				117 packets reassembled ok//重组成功的封包数
				1 packet reassemblies failed　//重组失败的封包数
			- -e：显示额外的信息，比如socket path等
			- -r：显示内核路由表，等同于route -e
			- Recv-Q和Send-Q的解释
				- 注意，在不同套接字状态下，它们的含义不同：
				1、当套接字处于Established状态（Established）时，Recv-Q 表示OS持有的、尚未交付给应用程序的数据的字节数；而 Send-Q 表示已经发送给对端应用，但对端应用尚未ack的字节数。
				void
				2、当套接字处于监听状态（Listening）时，Recv-Q 表示当前全连接队列的长度。而 Send-Q 表示全连接队列的最大长度，其值为min(backlog, somaxconn)。
				void
				注意，Listening状态时，Recv-Q的最大值为Send-Q+1，即：min(backlog, somaxconn)+1。
				void
				之所以加1，是因为OS内核在判断队列是否已满时，用的是>（应该用>=），这导致当已创建成功的连接数量正好等于min(backlog, somaxconn)时，还会再多创建一个tcp连接，最终结果就是：min(backlog, somaxconn)+1。
		- 场景
			- 1.列出所有tcp端口，包括listen和非listen状态
				- netstat -ta
			- 2.列出所有处于listen状态的tcp端口
				- netstat -tl
			- 3.显示各个协议的统计信息
				- netstat -s
			- 4.显示tcp统计信息
				- netstat -st
			- 5.初步检测你的系统有没有受到DDOS攻击
				- netstat -n -p | grep SYNC_REC | wc -l
	- ss ^05f0aa03-2235-78f9
		- 用法
			- -a：显示所有sokcets，包括LISTEN和非LISTEN
			- -l：只显示LISTEN状态的socket
			- -n：不解析服务器名字，显示数字和端口
			- -p：显示进程信息
			- -t：只显示tcp连接
			- -u：只显示udp连接
			- -x：只显示unix连接
			- -s：连接信息汇总
	- iperf
		- 用法
			- -f[kmKM]：分别表示以Kbits，Mbits,KBytes,MBytes显示报告
			- -s：以server模式启动
			- -c：以client模式启动
			- -p：指定端口号
			- -u：使用udp协议
			- -t：表示测试多久，一般指定在client端
			- -m：在结果中打印tcp mss值
			- -N：禁止使用Nagle算法
		- 场景
			- 测试tcp吞吐量
				- server
					- iperf -s -p 10000
				- client
					- iperf -c 192.168.1.102 -p 10000
			- 测试udp吞吐量
				- server
					- iperf -s -p 10000 -u
				- client
					- iperf -c 192.168.1.102 -p 10000 -u
	- ab ^9bb2bb4c-cb99-a0ee
		- 用法
			- -c：并发数
			- -n：总请求数
			- -s：设置每个请求的超时时间
			- -r：套接字接收错误时仍然继续执行
		- 注意
			- 测试高并发，需要提前修改进程能打开的最大文件描述符的大小：
			ulimit -n 10240
		- 场景
			- 测试某个服务的性能
			ab -c 100 -n 10000 http://httpbin.org/ip
			- Failed requests:　//失败的请求数；
			Non-2xx responses://非2xx回应的请求数；
			Requests per second://每秒完成的请求数；
			Time per request【１】:每个请求的平均处理时间；
			Time per request【２】:引入并发因素后，每个请求的平均处理时间；
			Transfer rate: //每秒数据传输量，表示网络吞吐；
			备注：
			某些情况下Time per request【２】乘以concurrency，约等于Time per request【１】，希望这样有助于你理解这两者的区别。
	- hping3 ^d2fb9f64-95bf-29bd
		- 用法
			- 模式选择，默认tcp
				- --rawip：RAWIP模式
				- --icmp：ICMP模式
				- --udp：UDP模式
				- --scan：SCAN模式，指定扫描对应的端口
				- --listen：监听模式
			- -S：表示设置TCP协议的SYN(同步序列号)
			- -p：设置端口号
			- -c：发送的总封包数
			- -i：u100表示每隔100us发送一个网络帧
				- -i 1：表示每隔1秒发送一个网络帧；
				-i u100：表示每隔100微妙发送一个网络帧；
			- -a{hostname}：原地址欺骗
			- --rand-source：随机化源IP
			- --flood：尽量快的发包，无需再指定-i
		- 场景
			- 1.端口扫描
				- 扫描一个端口
					- hping3 192.168.1.102 --scan 80 -S
				- 扫描多个端口
					- hping3 192.168.1.102 --scan 80,8080 -S
			- 2.模拟DDOS攻击
				- SYN ddos攻击
					- hping3 -S -p 80 -i u 10 192.168.1.102
				- flood+随机源地址SYN攻击
					- hping3 -S -p 80 192.168.1.102 --flood --rand-source
			- 3.伪造源IP地址
				- 伪造源地址为10.0.0.1给192.168.1.102的80端口发送syn包
					- hping3 -S -p 80 -a 10.0.0.1 -S 192.168.1.102
	- ping
		- 用法
			- -n：不会进行名称解析
			- -s{packetsize}：需要指定发送封包的大小
			注意：{packetsize} + 8 + 20应该小于MTU否则会进行IP分包
			- -M{pmtudisc_opt}：选择Path MTU发现策略
				- do：禁止分片
				- want：package太大时执行分片
				- dont：不设置DF flag
			- 例子
				- ping 192.168.1.102 -c 1
	- nethogs
		- 用法
			- 排序显示每个进程所使用的网络带宽
				- nethogs -d 2 -s
			- -d{seconds}：指定刷新频率
			- -s：按照网络发送量排序
			- 交互参数
				- m：切换byte, kb, mb
				- r：按照接收顺序排序
				- s：按照发送量排序
	- iftop
		- 用法
			- 界面参数说明：
			=>代表发送数据
			<=代表接收数据
			TX：发送流量（过去 2s 10s 40s ）
			RX：接收流量（过去 2s 10s 40s ）
			TOTAL：总流量
			Cumm：运行iftop到目前时间的字节总量
			peak：过去40s的流量峰值
			rates：分别表示过去 2s 10s 40s 的平均流量
			备注：流量的单位是Bytes/s，也就是传输速度。
			- -i ${dev}：设定监测的网卡
			- -B：以Bytes为单位显示流量（默认是bits）
			- -n：不适用host信息、而是使用ip地址+端口的的方式来显示
			- iftop -i eth0 -B -n
- 调优实践 ^0bf2abae-a491-2a21
	- 1.ping不通服务器，该从哪方面去调试？
		- Sub title
			- Sub title
				- 1. 【物理层】查看网线接口灯是否正常
			- Sub title
				- 绿灯是链路指示灯,黄灯是信号指示灯。
				１、黄灯闪动,绿灯长亮
				表示链路正常,正在通信中；
				２、黄灯不亮,绿灯长亮
				表示链接正常,不过目前没有数据通信；
				３、黄灯不亮,绿灯闪动
				表示链路不稳定，存在比如线头接触不良等问题
		- 2.【数据链路层】ifconfig查看相应的网络接口是否存在RX errors或者TX errors
			- watch -d ifconfig eth0
		- 3.【arp层】查看本地arp缓存中关于目标ip地址的mac地址是否正确？
			- arp -e
		- 4.【网络层】执行route查看针对目标IP的出口设备是否正常？
		有时docker bridge创建172打头的路由规则可能会导致路由错误
		- 5.【本机的软件防火墙】通过iptables -L查看是否有针对目标服务器地址可疑规则
		- 6.【第三方防火墙】和服务器机器是否直连，中间有没有通过其他设备，该设备是否有防火墙规则设定？
			- iptables -L
		- 7.【tcp层】通过nmap -sS -v 172.21.84.140或者nmap -sT -v 172.21.84.140扫描服务器开关机状态和存活端口号
	- 2.对端socket发出RST报文，导致连接异常关闭，该怎么分析？
		- 分析过程
			- Sub title
				- 1. 通过wireshark或者tcpdump分析tcp通信过程
			- 2.RST是发生在3次握手过程吗？是否在向一个未监听的端口发送SYN封包？
			- 3.客户端和服务端程序有任何一方发生了异常退出？
			- 4.是否在已经关闭的socket上收到了数据？
			- 5.客户端和服务端有任何一方提前close退出？
		- 案例
			- 在已经关闭的socket上收到了数据，底层协议栈会发送RST
			- 接收方应用程序未接收完接收缓冲区的数据，就提前close退出底层协议会发送RST
	- 3.压测nginx服务时网络延迟居高不下如何解决？
		- 环境搭建
			- nginx打开nagle算法
			vi /etc/nginx/nginx.conf
			http {
			...
			tcp_nodelay off;
			...
			}
			客户端使用ab工具并发压测：
			$ ab -c 100 -n 10000 -k http://172.21.84.207:8081/
			结果：
			Requests per second: 2259.76 [#/sec] (mean)
			Time per request: 44.253 [ms] (mean)
			nginx关闭nagle算法
			vi /etc/nginx/nginx.conf
			http {
			...
			tcp_nodelay on;
			...
			}
			再测压测
			$ ab -c 100 -n 10000 -k http://172.21.84.207:8081/
			结果：
			Requests per second: 20316.37 [#/sec] (mean)
			Time per request: 4.922 [ms] (mean)
			【附】本例使用的完整的nginx.conf文件如下：
			workerprocesses 1; events { workerconnections 1024;
			}
			http {
			server {
			listen 8081;
			servername localhost; location / { root /var/www/html; #html访问路径 index index.html index2.htm; #html文件名称 } } sendfile on; tcpnodelay on;
			keepalive_timeout 65;
			include /etc/nginx/conf.d/*.conf;
			}
		- 分析过程
- 调优方法 ^258eb8bb-e4e3-ea7f
	- 数据链路层
		- 网卡驱动优化
			- NAPI：中断+轮询
			- 为网卡中断配置cpu亲和性（smp_affinity），将这些中断处理程序调度到不同的CPU上执行
		- DPDK
			- 跳过逻辑复杂的Linux网络协议栈，直接由用户进程轮询的方式处理网络请求
	- 传输层
		- tcp
			- tcp TIME_WAIT优化
				- 1.增大TIME_WAIT状态连接的数量：net.ipv4.tcp_max_tw_buckets
					- tcp
					max
					tw
					buckets控制kernel中最多存在的TIME
					WAIT数量。
				- 2.减少net.ipv4.tcp_fin_timeout,让处于FIN状态的tcp连接尽早释放
				- 3.开启端口复用net.ipv4.tcp_tw_reuse，这样被TIME_WAIT状态占用的端口，很快被用于新的连接
			- 增加可用端口号或者文件数
				- Sub title
					- 1. 增大本地端口范围net.ipv4.ip_local_port_range,这样就可以支持更多连接，提高服务并发能力
				- 2.linux里，一切皆是文件，socket连接也是，可增加最大文件描述符的数量
					- ulimit -n 10240
			- SYN相关优化
				- 1.增大TCP半连接的最大数量：net.ipv4.tcp_max_syn_backlog
				- 2.减少SYN_RECV状态的连接重传SYN+ACK包的次数：net.ipv4.tcp_synack_retries
			- 其他优化
				- tcp nagle算法
					- 启用时可以提高小包场景下网络利用率，但是同时也会增加网络延迟
					- tcp延迟确认
						- 提高某些场景下的网络利用率
		- udp
			- 1.增大UDP的缓冲区大小
			- 2.跟前面TCP部分提到的一样，增大本地端口号的范围
			- 3.根据MTU大小，调整UDP数据包的大小，减少或者避免分片的发生
		- 配置套接字缓冲区大小
		参考：linux-4.9.229/Documentation/sysctl/net.txt
			- net.core.optmem_max:每隔套接字允许的醉倒辅助缓冲区大小
			- net.core.rmem_max：醉倒接收套接字缓冲区大小（以字节为单位）
			- net.core.wmem_max：最大发送套接字缓冲区大小（以字节为单位）
	- 应用程序层
		- 1.使用epoll取代selec和poll
		- 2.尽量使用连接池，比如postgres和redis编程都支持连接池的方式，可以避免每次请求都要建立三次握手
		- 3.为socket配置较大的套接字缓冲区SO_SNDBUF和SO_RCVBUF
		- 4.使用缓存技术，缓存一部分实时性没那么高的数据，减少不必要的网络访问

## 内存
- 基本原理 ^ccfb293d-1c54-0ffa
	- linux内核内存管理
		- 【批发】linux内核基于伙伴算法管理物理页内存
		- 【零售】linux内核基于slab管理内存
		- linux内核所用的物理内存大小统计
	- linux进程内存管理
		- 虚拟内存->内存映射->物理内存
			- 进程独享虚拟地址空间（32位）0-3G
			- 进程内分段管理内存空间
				- 代码段
				- 数据段
				- heap malloc()
				- stack
				- 文件映射，匿名映射 mmap()
			- 进程内存按照用途进行分类
				- anonymous
					- private
						- stack
						- malloc
						- brk
						- sbrk
						- mmap(PRIVATE, ANON)
					- shared
						- POSIX shm*
						- mmap(SHARED,ANON)
				- File-backed
					- private
						- mmap(PRIVATE,fd)
						- pgms/shared libs
					- shared
						- mmap(SHARED, fd)
		- 物理内存
			- 进程所有物理内存大小统计
				- PSS:
				一个进程所使用的内存可通过PSS和RSS来衡量。
				计算进程的Pss:
				$ cat /proc/1/smaps | grep Pss | awk '{total+=$2}; END {print total}'
					- 把一个共享库占用的内存，分摊到使用了这个共享库的各个进程头上
				- RSS(不合理)
					- 把共享库占用的内存直接加到每个进程的头上
				- USS
					- 进程独占的物理内存（不包含共享库占用的内存）
	- 内存回收
		- 回收时机
			- 内存紧缺回收（alloc_pages的时候）
			- 周期性内存回收
				- linux内存回收总结：从swapd出发到回收3部曲
			- 手动回收
				- echo 1 > /proc/sys/vm/drop_caches
					- clean page caceh
				- echo 2 > /proc/sys/vm/drop_caches
					- shrink slab(dentry文件夹 & inode文件)
				- echo 3 > /proc/sys/vm/drop_caches
		- 回收方式
			- 页回写
				- 直接释放物理页面
			- 页交换
				- 回写到swap分区，然后释放物理页面
			- OOM Killer
- 性能指标 ^449bc9fd-b431-4359
	- 系统内存使用量
	buffer,cache,used
		- 相关工具
			- /proc/meminfo
			- free
			- sar -r 1
			- vmstat
	- 系统内存余量
	free, available
		- available等于“空闲内存减去所有zones的lowmem reserve和high watermark，再加上page cache和slab中可以回收的部分“
	- 进程虚拟内存
		- 相关工具
			- /proc/{id}/maps
			- pmap -p 1
	- 进程内存使用量
		- 相关工具
			- ps -aux
			- top
				- RES：常驻内存大小
				RES=RSan+RSfd+RSsh
				- RSan：常驻匿名内存大小
				- RSfd：常驻文件映射内存大小
				- RSsh：常驻被锁定内存大小
				- SHR：共享内存大小
			- /proc/{pid}/status
			- smem -k -s rss|more
	- 缓存与缓存区命中率
		- 缓存命中率，是指直接通过缓存获取数据的请求次数，占所有数据请求次数的百分比。
		- 相关工具
			- cachestat/cachestat-bpfcc(系统整体)
				- HITS ，表示page cache命中的次数；
				MISSES ，表示page caceh未命中的次数；
				DIRTIES， Number of dirty pages added to the page cache；
				BUFFERS
				MB，表示 Buffers 的大小，以 MB 为单位； CACHED
				MB，表示 Cache 的大小，以 MB 为单位；
				HITRATIO，表示 page cache 命中率；
			- cachetop/cachetop-bpfcc（进程）
			- pcstat（进程&文件）
	- swap分区使用量
		- swap分区的作用是在系统物理内存不足时,将一部分物理内存中的数据交换到swap分区（磁盘上），从而把这部分物理内存释放出来给需要的程序来使用。
		一、哪部分内存会被交换到swap分区？
		１、匿名页(AnonPages)；
		２、Shmem(基于tmpfs实现)虽然未统计在AnonPages里，但它们背后没有硬盘文件，所以也是需要交换区的。
		二、从进程角度看，以下的函数或者机制分配的内存在物理内存不足时会被交换到swap分区，包括：
		stack
		malloc()
		brk()/sbrk()
		mmap(PRIVATE, ANON)
		POSIX shm*
		mmap(SHARED, ANON)
		tmpfs
		- 相关工具
			- free(系统整体)
			- sar -S 1(系统整体)
			- smem -k (进程)
	- 内存泄露情况
		- 相关工具
			- memleak -a -p {pid}
	- 缺页异常(主、次)
		- 缺页异常：cpu拿到虚拟地址，让MMU进行地址转换的时候，MMU找不到虚拟地址的页表映射关系。
		主缺页：需要从磁盘加载 memory page；
		次缺页：不需要从磁盘加载 memory page
		- 相关工具
			- 进程自启动以来发生的缺页事件的总和
			ps -eo min_flt,maj_flt,cmd|more
			- 进程每秒发生缺页错误次数
			pidstat -r
- 工具汇总 ^3fe0d538-f438-7367
	- free
		- 用法
			- buff
				- 直接读写块设备所用的缓存
				- 文件系统元数据metadata比如superBlock所使用的缓存页
			- cache
				- Cached
					- 磁盘上的文件
					- tmpfs上的文件(Shmem)
				- SReclaimable
					- SReclaimable表示slab中可回收的部分。调用kmemcachecreate()时加上SLABRECLAIMACCOUNT标记，表明是可回收的，计入SReclaimable，否则计入SUnreclaim。
					在dcacheinit() --- fs/dcache.c 和inodeinit() -- fs/inode.c
					里在调用kmemcachecreate的时候都指定了SLABRECLAIMACCOUNT标记，表示dentry和inode占用的slab内存是可回收的。
				- Doesn't inlcude SwapCached
			- used=total-free-buffers-cache
			- free
			- available
	- sar
		- 用法
			- sar -S -r 1
			- -r：表示显示内存使用情况
				- kbcommit，表示当前系统负载需要的内存。它实际上是为了保证系统内存不溢出（不超出），对需要内存的估计值。
				%commit，就是这个值相对总内存的百分比，因为commit统计的是RAM+swap，所以%commit可能会大于100%
			- -S：表示显示Swap使用情况
				- kbswpcad：其实就是swap文件的file cache。
				kbswpcad = SwapCached(来自/proc/meminfo)
	- vmstat
		- 用法
			- -f：显示系统启动到今创建的所有进程数
			- -S：使用指定单位显示，参数有k,K,m,M分别代表1000,1024,1000000,1048567字节（byte）。默认单位为K(1024bytes)
			- -a：显示活跃和非活跃内存
			- -s：内存使用详情
			- -m：显示slab详情
			- -d：磁盘读写的详情
			- -p：显示指定磁盘分区统计信息
	- cachestat/cachestat-bpfcc
		- HITS ，表示page cache命中的次数；
		MISSES ，表示page caceh未命中的次数；
		DIRTIES， Number of dirty pages added to the page cache；
		BUFFERS
		MB，表示 Buffers 的大小，以 MB 为单位； CACHED
		MB，表示 Cache 的大小，以 MB 为单位；
		HITRATIO，表示 page cache 命中率；
		- 用法
			- 提供整个系统的page cache的读写命中情况
	- cachetop/cachetop-bpfcc
		- 用法
			- 提供每个进程的page cache读写命中的情况
	- pcstat
		- 安装方法：
		$ export GOPATH=~/go
		$ go get github.com/tobert/pcstat
		$ cp -rfa $GOPATH/bin/pcstat /bin
		- 用法
			- 查看文件的缓存大小以及缓存比例：
			$pcstat  ./hello
			- 查看进程打开的所有文件的缓存大小以及缓存比例：
			$pcstat -pid {pid}
	- hcache
		- go version > 1.12
		【安装】
		git clone https://github.com/silenceshell/hcache.git
		cd hcache
		make build
		sudo cp hcache /usr/local/bin/
		- 用法
			- 输出系统中前10大使用缓存最多的文件：
			hcache --top 10
			- 只显示基本名字：
			hcache --top 10 -basename
	- memleak
		- memleak跟踪内存申请和释放请求。
		【实现原理】
		在跟踪某个进程时，memleak会追踪libc中的分配函数，具体来说包括：malloc、calloc、realloc、valloc、memalign、pvalloc、aligned dalloc和free； 当跟踪所有进程时，memleak追踪包括kmalloc/kfree、kmemcache
		alloc/kmemcache free，以及get free pages/free pages所分配的页面。
		- 用法
			- -a：表示显示每个内存分配请求的大小以及地址
			- -p：指定要检测的进程
			- -c：运行指定的命令，并只跟踪其分配，这只会跟踪libc分配器
			- -z{MIN_SIZE}：只捕获大于等于MIN_SIZE字节的内存泄露
			- -Z{MAX_SIZE}：只捕获小于等于MAX_SIZE字节的内存泄露
			- INTERVAL：每隔INTERVAL秒打印未释放的申请以及调用堆栈的摘要，缺省5s
			- 每隔1s打印一次进程3128的内存泄露统计
			memleak -a -p 3128
		- 限制
			- 1.当追踪的进程快速申请和释放内存时，memleak可能会带来很大的开销
			- 2.此工具仅适用于Linux4.6+
	- smem
		- 用法
			- 统计物理内存使用量，支持维度：process,user,mapping,systemwide
			- -k：显示单位后缀
			- -p：使用百分比显示
			- -u：显示用户占用内存信息swap/rss/uss/pss大小
			- -w：显示系统内存使用量，包括内核空间和用户空间
			- -m：统计mapping所用的物理内存
				- $ smem -m -k
				Map PIDs AVGPSS PSS
				/lib/x86_64-linux-gnu/libc-2.27.so 173 29.0K 5.1M
				第一列(Map)：
				表示被共享的文件名字；
				第二列(PIDs)：
				表示上述文件被几个进程共享；
				第三列(AVGPSS)：
				各个进程平均分摊的内存，AVGPSS＝PSS/PIDs
				第四列(PSS)：
				文件加载后，占用的物理内存；
			- -s{swap/pss/uss/rss}：按照进程对swap/rss/pss/uss的使用量排序
- 调优实践 ^1be257bb-642d-6d33
	- 1.linux c语言开发遇到常见的问题如何定位？
		- 分析过程
			- 1.查看系统总体内存用量，确定大致问题：
			vmstat -S -K 1
			- 2.对使用物理内存最多的20个进程进行监控，确定进程是否存在内存异常：
			watch -n 1 -d "smem -s  rss | tail -n 20"
			- 2.如果内存使用持续增加，进行内存泄露监控：
			memleak -a -p {pid} 1
			- 4.对其他内存使用量较高的进程进行review，主要关注如下部分：
			- malloc
			- brk()/sbrk()
			- mmap()
			- shmem()等
			- 5.进行代码层面的性能优化
	- 2.spark处理200w笔数据，有时候需要几秒，有时候需要 几十秒，原因何在？
		- 分析过程
			- 1.检查执行过程有没有设计文件的操作？
			lsof -p 28601|grep test.csv
			- 2.查看文件缓存命中情况：
			pcstat /home/user/test-data/test.csv
			- 3.记录测试结果
			- 4.清除文件缓存
			echo 1 > /proc/sys/vm/drop_caches
			- 5.查看缓存命中情况
			- 6.记录测试结果
			- 7.结论：由于文件缓存的作用，性能提升了10倍左右！
- 调优方法 ^44ece4dd-cf30-655c
	- 应用层面
		- 1.尽量使用缓存或者缓冲区来缓存数据
			- fluent-bit;
			void
			void
			flume;
			void
			void
			spark等
		- 2.考虑使用tmpfs代替磁盘目录
			- mount -t tmpfs -o size=1G tmpfs /tftpboot/spark
			- tmpfs是一种临时文件存储系统，它将数据保存在内存（RAM）中而不是物理硬盘上。由于内存的访问速度远高于传统硬盘或固态硬盘，因此当程序向tmpfs文件系统进行读写操作时，这些操作的速度会显著提高。
	- 系统层面
		- 1.减少swap使用个，比如减少swappiness大小
		- 2.限制进程内存资源
		- 3.使用HugePage（大页内存，4k->2M,1G等），提高TLB命中率
		- 4.通过/proc/{pid}/oom_odj，调整核心应用oom_score范围[-17, +15]，越大越容易被杀死