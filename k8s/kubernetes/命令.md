

## 常用网络命令

### 查看pod的网卡信息
```bash
kubectl exec -ti alertmanager-main-0 -n base-services -- sh -c 'cat /sys/class/net/eth0/iflink'
43
```
如果pod里面不支持执行命令，可以使用如下方式就进行查找

1. 查看pod的容器
```bash
# 查看pod的容器
crictl ps | grep ysp-ui-lzwd2
e81fa0489d6ed       71d9be26110de       9 minutes ago       Running             my-container                0                   3eb95c3598168       ysp-ui-lzwd2
```
2. 根据容器ID查看进程 `PID` 信息
```bash
# 根据容器ID查看进程PID信息
crictl inspect -o yaml e81fa0489d6ed | grep pid
          pid: 1
  pid: 2764398
      - type: pid
```
3. 根据 `PID` 查看网卡信息
```bash
# ls -l /proc/{pid}/ns/net  根据PID查看网卡信息
ls -l /proc/2764398/ns/net
```
4. 查看网络信息
```bash
# 通过/proc/<pid>/ns/net可以访问容器的网络命名空间。为了方便操作，可以创建符号链接到/var/run/netns/ 目录
ln -s /proc/2764398/ns/net /var/run/netns/pod_netns
# 查看网络信息，可以看到这里使用的是和宿主机的的64号网卡对应
ip netns exec pod_netns ip addr
...
4: eth0@if64: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default 
    link/ether 3a:e1:83:31:3d:57 brd ff:ff:ff:ff:ff:ff link-netnsid 0
    inet 100.66.218.186/32 scope global eth0
       valid_lft forever preferred_lft forever
    inet6 fe80::38e1:83ff:fe31:3d57/64 scope link 
       valid_lft forever preferred_lft forever
# 使用 ip link show | grep "^64:" 可以查看宿主机上对应的网卡， 如果容器没有创建网卡，那么默认就是都是4编号
ip link show | grep "^64:"
64: cali70d3ca51123@if4: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP mode DEFAULT group default 
    link/ether ee:ee:ee:ee:ee:ee brd ff:ff:ff:ff:ff:ff link-netns pod_netns
```
### 查看网络策略

1. 先查看当前命名空间中有哪些网络策略
```bash
$ kubectl get networkpolicies -n base-services
```
2. 再查看这些网络策略的具体进出规则
```bash
$ kubectl  describe networkpolicy -n base-services prometheus-k8s
...
Spec:
  PodSelector:     app.kubernetes.io/component=prometheus,app.kubernetes.io/instance=k8s,app.kubernetes.io/name=prometheus,app.kubernetes.io/part-of=kube-prometheus
  Allowing ingress traffic:
    To Port: <any> (traffic allowed to all ports)
    From: <any> (traffic not restricted by source)
  Allowing egress traffic:
    To Port: <any> (traffic allowed to all ports)
    To: <any> (traffic not restricted by destination)
  Policy Types: Egress, Ingress
```

## 容器操作命令

### 查看容器名和容器ID之间的对应关系

- 容器ID
- 容器名
- 使用CPU
- 内存
- 磁盘
- 使用 `INODES` 个数
```bash
$ crictl stats
CONTAINER           NAME                        CPU %               MEM                 DISK                INODES
03508c8c3a086       kube-scheduler              0.15                86.79MB             24.58kB             11
0b4aee216b2a8       config-reloader             0.27                9.802MB             32.77kB             12
```

## 常用的镜像操作命令

### `k8s` 中使用本地镜像

```bash
# -n k8s.io k8s中都需要指定这个命名空间，k8s会默认从这里拿镜像
ctr -n k8s.io image import ysp-ui.tar
# 查看对应镜像是否存在
ctr -n k8s.io images list | grep ui
# 将镜像修改成 ip + group + product + version的形式
# 将镜像前面修改成带有ip信息的tag，否则k8s会自动添加上docker.io
ctr -n k8s.io images tag docker.io/ysp/ui:1.0 10.161.40.240:30003/ysp/ysp-ui:latest
```
对应镜像拉取策略需要设置成本地优先或者仅本地

```yaml
containers:
	- name: my-container
	  image: 10.161.40.240:30003/ysp/ysp-ui:latest
	  #  Always 只在线拉取，IfNotPresent 优先本地，Never 只使用本地
	  imagePullPolicy: IfNotPresent
```

### 查看镜像
```bash
docker：docker images
criclt：crictl images
ctr：ctr -n k8s.io images list
```
### 删除镜像

```bash
docker：docker rmi [image-id]
criclt：crictl rmi [image-id]
ctr：ctr -n k8s.io images delete [image=id]
```
### 保存镜像

```bash
docker：docker save [docker.io/sipc/sipaas:V5.0.02.030.36](https://docker.io/sipc/sipaas:V5.0.02.030.36) -o sipaas_V5.0.02.030.36.tar
ctr：ctr -n k8s.io image export sipaas_V5.0.02.030.36.tar docker.io/sipc/sipaas:V5.0.02.030.36
```
### 加载镜像

```bash
docker：docker load -i sipaas_V5.0.02.030.36.tar
ctr：ctr -n k8s.io image import sipaas_V5.0.02.030.36.tar
```
### 打镜像tag

```bash
docker：docker tag docker.io/sipc/sipaas:V5.0.02.030.36 mcs/sipc/sipaas:V5.0.02.030.36
ctr：ctr -n k8s.io image tag docker.io/sipc/sipaas:V5.0.02.030.36 mcs/sipc/sipaas:V5.0.02.030.36
```
```bash
[root@k8smaster-82 ~]# ctr -n k8s.io image tag docker.io/sipc/sipaas:V5.0.02.030.36  mcs/sipc/sipaas:V5.0.02.030.36mcs/sipc/sipaas:V5.0.02.030.36[root@k8smaster-82 ~]# crictl images | grep sipaasdocker.io/mcs/sipc/sipaas                                                            V5.0.02.030.36               753e058aeb401       17.6MBdocker.io/sipc/sipaas                                                                V5.0.02.030.36               753e058aeb401       17.6MB 
```

### 拉取镜像

```bash
docker：docker pull [image:tag]
ctr: ctr -n k8s.io image pull --user admin:HaRb0r@1993 -k --platform linux/amd64 10.161.42.82:30003/goharbor/harbor-exporter:v2.8.4
```
### 推送镜像

```bash
docker：docker push [image:tag]
ctr: ctr -n k8s.io image push --user admin:HaRb0r@1993 -k --platform linux/amd64 10.161.42.82:30003/platform/calico/apiserver:v3.24.6
```
###  `ctr` 挂载镜像，查看镜像里的文件

```bash
ctr：ctr -n k8s.io image mount <image_name>[:<tag>] <mountpoint>
ctr: ctr image unmount <mountpoint>
```
## `k8s` 基础命令

### 查看Pod的标签信息

```bash
kubectl get pods -n base-services --show-labels
```

### 获取资源信息

```bash
kubectl get nodes         # 列出所有节点kubectl get pods          # 列出所有 Podkubectl get deployments  # 列出所有 Deploymentkubectl get svc           # 列出所有服务
```

###  描述资源详细信息

```bash
kubectl describe pod <pod-name>  # 描述指定 Pod 的详细信息kubectl describe node <node-name>  # 描述指定节点的详细信息
```

###  创建资源

```bash
kubectl create -f <file.yaml>  # 从文件创建资源
```

### 应用配置

```bash
kubectl apply -f <file.yaml>  # 应用配置到资源
```

### 删除资源

```bash
kubectl delete pod <pod-name>  # 删除指定 Podkubectl delete deployment <deployment-name>  # 删除指定 Deployment
```

### 扩展资源

```bash
kubectl scale deployment <deployment-name> --replicas=3  # 扩展 Deployment 到 3 个副本
```

### 日志

```bash
kubectl logs <pod-name>  # 获取 Pod 的日志kubectl logs -f <pod-name>  # 持续跟踪 Pod 的日志
```

### 编辑资源

```bash
kubectl edit deployment <deployment-name>  # 编辑指定 Deployment 的配置
```

### 滚动更新

```bash
kubectl rollout status deployment <deployment-name>  # 查看 Deployment 的滚动更新状态kubectl rollout undo deployment <deployment-name>  # 回滚到之前的 Deployment 版本
```

### 端口转发

```bash
kubectl port-forward pod/<pod-name> <local-port>:<container-port>  # 将本地端口转发到 Pod 的端口
```

### 节点排错

```bash
kubectl cordon node <node-name>  # 将节点标记为不可调度kubectl drain node <node-name>  # 清空节点上的 Pod，准备维护kubectl uncordon node <node-name>  # 将节点标记为可调度
```

### 资源配额和限制

```bash
kubectl create quota <quota-name> --hard=cpu=1,memory=1G  # 创建资源配额kubectl describe quota <quota-name>  # 描述资源配额
```

### 集群信息

```bash
kubectl cluster-info  # 显示集群信息，包括 master 和 nodes 的地址
```

### 配置文件

```bash
kubectl config view  # 查看合并后的 kubeconfig 文件kubectl config get-contexts  # 列出所有的上下文（cluster, user, namespace）
```

### 查看pod的CPU，内存
```bash
有的YsP版本可能没有kubectl top命令，请通过top等命令排查问题
与 kubectl get pod 的用法差不多
kubectl top pod -n 命名空间 查看某个产品下的pod的信息
kubectl top pod -A 查看所有pod的信息
```

## 标签

### 查询相关命名空间中的Pod标签

```bash
kubectl get pods -n base-services --show-labels
```
### 在相关命名空间中按照Pod标签查询

```bash
kubectl get pods -n base-services -l app=ui
```

### 查看node上的lables
通常结合pod的labels查看对应的pod是否能调度到Node上去
```bash
kubectl get nodes --show-labels
```

## `crictl`


- 查看具体Pod的进程ID

```bash
# 获取Pod name
kubectl get pod -A 
# 先查找容器ID
crictl ps | grep <pod-name>
# 根据容器ID获取进程的PID
crictl inspect <container-id> | grep -A 5 "pid"
# 宿主机上查看对应进程信息
ps aux | grep pid
```

### `crictl inspect`
- 查看容器的详细运行信息，环境变量配置等
```bash
crictl inspect <container-id> 
```




## `kubectl`

使用 `kubectl` 命令时，如果需要查看发送到 `API Server` 的 `HTTP` 请求，则可以将日志级别设置为8。
```bash
$ kubectl --v=8 version
```

### `kubectl run`

- 创建并运行一个指定的镜像
```bash
$ kubectl run NAME --image=image [params]
```



### `kubectl port-forward`

- 端口转发
```bash
$ kubectl port-forward -n base-services  svc/prometheus-k8s 9090:9090 --address 10.161.40.73
```

- 将pod的端口转发到宿主机
```bash
$ kubectl port-forward -n monitoring service/grafana 3000:80
```



### `kubectl get`

#### `kubectl get svc`

一般情况下 `service` 的两种使用场景

![](attachments/Pasted%20image%2020250120145616.png)

- 通过 `get svc` 获取 `Cluster-ip` 地址
```bash
$ kubectl get svc kubernetes -o wide
NAME                  TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE       SELECTOR
kubernetes            ClusterIP   10.96.0.1       <none>        443/TCP          166d      <none>
```

- 获取对应空间中有多少service类型
可以用来查看service类型节点的cluster-ip和端口映射关系。
```bash
$ kubectl get service -n base-services
NAME                    TYPE        CLUSTER-IP    EXTERNAL-IP   PORT(S)         AGE
prometheus-k8s          NodePort    10.96.0.184   <none>        9090:30090/TCP  8d
```

- 获取 `ConfigMap`类型对象的配置，并按照 `yaml` 形式输出
根据输出的 `mode: ipvs` 可以确定使用的网络负载均衡模式是 `iptables` 还是 `ipvs`。

```bash
$ kubectl get configmap kube-proxy -n kube-system -o yaml
```
- 查看具体 `service` 下 `ClusterIP` 和`NodeIP` 之间的对应关系
```bash
$ kubectl describe svc prometheus-k8s -n base-services
Name:                     prometheus-k8s
Namespace:                base-services
Labels:                   app.kubernetes.io/component=prometheus
                          app.kubernetes.io/version=3.1.0
Annotations:              <none>
# 选择器下的 labels 对应的 Endpoints 中必须有，否则就失效
Selector:                 app.kubernetes.io/component=prometheus,app.kubernetes.io/instance=k8s,app.kubernetes.io/name=prometheus,app.kubernetes.io/part-of=kube-prometheus
Type:                     NodePort
IP Family Policy:         SingleStack
IP Families:              IPv4
IP:                       10.96.1.210      # 对应的cluster ip
IPs:                      10.96.1.210
Port:                     web  9090/TCP
TargetPort:               web/TCP
NodePort:                 web  30090/TCP

# ClusterIP 地下对应的Endpoints
Endpoints:                10.226.152.110:9090,10.237.248.123:9090 
Session Affinity:         ClientIP
External Traffic Policy:  Cluster
Events:                   <none>
```
#### `kubectl get enpoints`

- 通过 `get endpoints` 获取对应 `service` 内部的 `IP` 地址
```bash
$ kubectl get endpoints kubernetes
NAME         ENDPOINTS        AGE
kubernetes   10.0.2.15:8443   166d
```
#### `kubectl get enpointslice`

- 获取服务节点分片
```bash
$ kubectl get endpointslice -n base-services 
NAME                          ADDRESSTYPE   PORTS            ENDPOINTS                                     AGE
alertmanager-main-4kh4n       IPv4          8080,9093        10.226.152.198,10.225.160.73,10.226.152.200   15d
```
- 获取对应分片的拓扑信息和 `svc` 类似
```bash
$ kubectl describe endpointslice alertmanager-main-4kh4n
```


#### `kubectl get pod`


- 获取一个节点所有的 `yaml` 配置
```bash
$ $kubectl get pod prometheus-k8s-0 -n base-services -o yaml
```

```
- 在获取到service类型之后可以通过一下命令查看对应service的yaml配置
这里的 `prometheus-k8s` 是service name
```

```bash
$ kubectl get service prometheus-k8s -n base-services -o yaml
apiVersion: v1
kind: Service
metadata:
  name: prometheus-k8s
  namespace: base-services
spec:
  clusterIP: 10.96.0.184
  clusterIPs:
  - 10.96.0.184
  externalTrafficPolicy: Cluster
  internalTrafficPolicy: Cluster
  - name: web
    nodePort: 30090
    port: 9090
    protocol: TCP
    targetPort: 9090
  selector:
    app: prometheus
    app.kubernetes.io/component: prometheus
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/part-of: kube-prometheus
    prometheus: k8s
  # 会话亲和性，配置了亲和性同一个外部ClientIp在超时之前一直会访问同一个Pod
  sessionAffinity: ClientIP
  sessionAffinityConfig:
    clientIP:
      timeoutSeconds: 10800
  type: NodePort
```
- 获取所有监听类型的Pod资源
```bash
$ kubectl get all -n base-services
```
- 不知道获取空间里面什么具体资源时可以通过 `get all` 获取整个空间的缩略信息
```bash
$ kubectl get all -n base-services
```

- 获取所有命名空间
```bash
$ kubectl get namespaces
```


```bash
# 获取自定义资源类型  
kubectl get crd  
# 获取创建的Service  
kubectl get svc  
# 编辑Service的配置，比如将对应的服务类型修改为NodePort，NodePort只是Service的一种类型  
kubectl edit svc prometheus-k8s 
```  

---
### `kubectl describe` 输出节点的详细信息

- 输出命名空间位`base-services`节点类型为`statefulset`类型节点的详细信息
```bash
$ kubectl describe statefulset prometheus-k8s -n base-services
```



#### `kubectl describe node <nodename>`
使用该命令能查看如下信息：
- 节点的ip地址信息
- 节点上运行的pod都是哪些
- 对应pod的资源使用和限制情况，主要有CPU，内存

- 查看节点IP地址以及相关pod内存CPU等相关配置信息
```bash
[root@k8snode-4 ~]# kubectl describe node k8smaster-1
Name:               k8smaster-1
Roles:              control-plane
Labels:             beta.kubernetes.io/arch=amd64
                    beta.kubernetes.io/os=linux
                    harborMasterk8smaster-1=yes
                    host-role=ysp-master
                    kubernetes.io/arch=amd64
                    kubernetes.io/hostname=k8smaster-1
                    kubernetes.io/os=linux
                    nginx-ingress-515=yes
                    node-role.kubernetes.io/control-plane=
                    node.kubernetes.io/exclude-from-external-load-balancers=
                    role-master=true
Annotations:        csi.volume.kubernetes.io/nodeid: {"csi.tigera.io":"k8smaster-1"}
                    kubeadm.alpha.kubernetes.io/cri-socket: unix:///run/containerd/containerd.sock
                    node.alpha.kubernetes.io/ttl: 0
                    projectcalico.org/IPv4Address: 10.161.30.138/24
                    projectcalico.org/IPv4IPIPTunnelAddr: 10.254.152.0
                    volumes.kubernetes.io/controller-managed-attach-detach: true
CreationTimestamp:  Thu, 06 Mar 2025 14:45:41 +0800
Taints:             <none>
Unschedulable:      false
Lease:
  HolderIdentity:  k8smaster-1
  AcquireTime:     <unset>
  RenewTime:       Thu, 20 Mar 2025 15:26:08 +0800
Conditions:
  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message
  ----                 ------  -----------------                 ------------------                ------                       -------
  NetworkUnavailable   False   Tue, 18 Mar 2025 19:26:26 +0800   Tue, 18 Mar 2025 19:26:26 +0800   CalicoIsUp                   Calico is running on this node
  MemoryPressure       False   Thu, 20 Mar 2025 15:26:10 +0800   Fri, 14 Mar 2025 16:44:04 +0800   KubeletHasSufficientMemory   kubelet has sufficient memory available
  DiskPressure         False   Thu, 20 Mar 2025 15:26:10 +0800   Fri, 14 Mar 2025 16:44:04 +0800   KubeletHasNoDiskPressure     kubelet has no disk pressure
  PIDPressure          False   Thu, 20 Mar 2025 15:26:10 +0800   Fri, 14 Mar 2025 16:44:04 +0800   KubeletHasSufficientPID      kubelet has sufficient PID available
  Ready                True    Thu, 20 Mar 2025 15:26:10 +0800   Fri, 14 Mar 2025 16:44:04 +0800   KubeletReady                 kubelet is posting ready status
Addresses:
  InternalIP:  10.161.30.138
  Hostname:    k8smaster-1
Capacity:
  cpu:                16
  ephemeral-storage:  51136Mi
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  memory:             32600536Ki
  pods:               600
Allocatable:
  cpu:                14
  ephemeral-storage:  50938983180
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  memory:             26309080Ki
  pods:               600
System Info:
  Machine ID:                 bb92c21e05f24fd991c1caf1b4575b79
  System UUID:                05024d56-3a3c-5cd1-9821-2caeba06eb14
  Boot ID:                    8d4e0730-11c3-46a8-ac9b-abf6146b60ad
  Kernel Version:             5.14.0-503.26.1.el9_5.x86_64
  OS Image:                   Red Hat Enterprise Linux 9.4 (Plow)
  Operating System:           linux
  Architecture:               amd64
  Container Runtime Version:  containerd://1.6.27
  Kubelet Version:            v1.26.12
  Kube-Proxy Version:         v1.26.12
PodCIDR:                      10.224.0.0/24
PodCIDRs:                     10.224.0.0/24
Non-terminated Pods:          (81 in total)
# 这里的百分比，是占总可分配资源的百分比，也就是要求的资源占用机器可分配资源的比值
  Namespace                   Name                                   CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age
  ---------                   ----                                   ------------  ----------  ---------------  -------------  ---
  base-services               alp-15-855d557998-mjtfz                0 (0%)        0 (0%)      50Mi (0%)        500Mi (1%)     5d23h
  base-services               etcd-7-554cbb46d8-zp6sp                0 (0%)        0 (0%)      50Mi (0%)        2Gi (7%)       5d23h

```



### `kubectl explain`

- 查看 `pod` 节点下对应的 `yaml` 能配置哪些字段以及对应字段的解释说明。
```bash
$ kubectl explain pod.spec.containers
```

```bash
kubectl create secret generic user --from-literal=name=root $out
```

### `kubectl logs`

- 查看pod日志
```bash
kubectl logs prometheus-k8s-0 -n moniting
```


### `kubectl top`

- 查看 `prometheus pod` 资源使用情况
```bash
kubectl get pod prometheus-k8s-0 -n moniting
```
- 查看该命令空间下所有 `pod` 的资源使用情况
```bash
kubectl top pod  -n base-services 
```


### `kubectl` 其他命令


- 编辑Service的配置，比如将对应的服务类型修改为`NodePort，NodePort`只是`Service`的一种类型  
```bash
$ kubectl edit svc prometheus-k8s 
```


### `kubectl create`


#### 只输出 `yaml` 模板，不创建
```bash
export out="--dry-run=client -o yaml"  
kubectl create deploy ngx-dep --image=nginx:alpine $out
```
```bash
export out="--dry-run=client -o yaml"        # 定义Shell变量  
kubectl create cm info $out  
# 不过为了提阿加data字段通常会加上 --from-literal=k=v 字段  
kubectl create cm info --from-literal=k=v $out
```

1. kubectl create 命令只是简单地创建资源对象，它不会去检查或者处理对象的注解数据，所以它不会因为注解数据过大而报错。
2. kubectl apply 命令则会对资源对象进行更复杂的处理。在创建或者更新资源对象时，它会将整个资源对象的配置数据（包括注解数据）保存在 kubectl.kubernetes.io/last-applied-configuration 注解中。这样在以后的 apply 操作中，kubectl 就可以通过比较这个注解中的配置数据和当前的配置数据，来决定哪些字段需要更新，哪些字段不需要更新。由于这个原因，如果你的注解数据过大，超过了 Kubernetes 对注解数据大小的限制，那么 kubectl apply 就会报错。

因此，在 `kube-prometheus`项目中，因为注释都是超过限制的，只能使用 `kubectl create` 命令来创建资源对象。

### `kubectl exec`

- 查看pod的环境变量
```bash
kubectl exec <pod-name> -- env
```
- 进入Pod的bash环境，如果支持的话
```bash
kubectl exec -it  <pod-name> -- bash
```

### `kubectl cp`

- 将文件从容器复制到宿主机
```bash
# 将容器中的文件复制到宿主机的 `/tmp` 目录下
kubectl cp nginx-6bddddbc78gh-sfdcv:/etv/fstab /tmp 
```
- 将文件从宿主机复制到容器
```bash
kubectl cp /local/path/to/file.txt mynamespace/my-pod:/remote/path/ -c my-container
```


### `kubectl expose`
- 可以通过 `expose` 快速为 Pod示例创建 `Service`
```bash
kubectl expose deployment webapp
```



### `cAdvisor (Container Advisor)`

可用于查询容器指标的数据

- `container_cpu_usage_seconds_total`: 容器的CPU使用总量。
- `container_memory_usage_bytes`: 容器的内存使用量。
- `container_network_receive_bytes_total`: 容器接收的网络字节数。

- `cpu` 使用统计
pod:container_cpu_usage_seconds_total:sum - 自定义缩写

等价于
max by(pod, node, host_ip, pod_ip, namespace) (max by(pod) (rate(container_cpu_usage_seconds_total{image!="",job="kubelet", node="k8snode-node-03"}[2m]) * 100) * on(pod) group_right() (kube_pod_info))




## 添加自定义命令
可以通过 `kubernetes` 的插件机制实现对 `kubectl` 命令的扩展。
```bash
# 1. 插件以可执行文件形式呈现，需要以 kube-开头
# 2. 创建一个 kube-hello 的可执行文件，然后将可执行文件移动到 /usr/local/bin 下
# 3. 使用kubectl hello查看效果
kubectl hello
# 使用 kubectl plugin list可以查看已经安装的插件列表
kubectl plugin list 
```




## 其它命令

### 5.3.4 非pod服务的运行状态

dp的运行状态 systemctl status tomcat

harbor的运行状态，若是装的YsP3.1 YsP3.5，则用 systemctl status harbor，更具体的，用 docker ps | grep harbor 查看harbor容器是否都为healthy。若是装的YsP3.7，则直接通过 kubectl get pod -A | grep harbor查看harbor的运行状态

docker的运行状态 systemctl status docker

如果这些服务运行不正常，尝试用 systemctl restart 服务名 重启该服务，若报错，请按照提示查看错误日志或者查看系统日志 /var/log/messages


## `journalctl`

`system` 系统中查看 `kubelet` 日志
```bash
sudo journalctl -u kubelet -f
```



## `ctr` 命令


### `ctr tag`

因为所有k8s使用的镜像都是默认使用用户组 k8s.io因此如果容器编排工具是Kubenetes，加载镜像时需要指定 `-n k8s.io`

```
ctr -n k8s.io images tag docker.io/library/ui:v1.0.0.0 platform/ui:latest
```